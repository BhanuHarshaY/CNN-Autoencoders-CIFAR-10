{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHmKxSxXx/WanqMSh6jALl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhanuHarshaY/CNN-Autoencoders-CIFAR-10/blob/main/Assignment10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ASSIGNMENT10 |OBJECT RECOGNITION (CIFAR-10)|AUTHOR: BHANU HARSHA Y | DT: 14/08/25**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bAh17BZfVhn9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q6-rEL9k5yZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd17e06-fb8d-4445-8146-a98610331710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported all required libraries!\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# I set random seed to 42 for reproducability\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"Imported all required libraries!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1) DATA COLLECTION AND UNDERSTANDING THE DATASET:**"
      ],
      "metadata": {
        "id": "hCTU6UISjTOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading CIFAR10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#dataset info\n",
        "print(\"CIFAR-10 Dataset Overview:\")\n",
        "print(f\"Training set shape: {x_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test set shape: {x_test.shape}\")\n",
        "print(f\"Test labels shape: {y_test.shape}\")\n",
        "print(f\"Data type: {x_train.dtype}\")\n",
        "print(f\"Min pixel value: {x_train.min()}\")\n",
        "print(f\"Max pixel value: {x_train.max()}\")\n",
        "\n",
        "# Data Normalization\n",
        "def normalize_images(images):\n",
        "\n",
        "    return images.astype('float32') / 255.0\n",
        "\n",
        "x_train_normalized = normalize_images(x_train)\n",
        "x_test_normalized = normalize_images(x_test)\n",
        "\n",
        "\n",
        "print(\"Data After Normalization:\")\n",
        "print(f\"Normalized training data type: {x_train_normalized.dtype}\")\n",
        "print(f\"Normalized min value: {x_train_normalized.min():.4f}\")\n",
        "print(f\"Normalized max value: {x_train_normalized.max():.4f}\")\n",
        "print(f\"Normalized mean: {x_train_normalized.mean():.4f}\")\n",
        "print(f\"Normalized std: {x_train_normalized.std():.4f}\")\n",
        "\n",
        "#Alternative approach standardization\n",
        "print(\"\\nAlternstive approach: Standardizartion\")\n",
        "def standardize_images(images):\n",
        "\n",
        "    mean = np.mean(images, axis=(0, 1, 2), keepdims=True)\n",
        "    std = np.std(images, axis=(0, 1, 2), keepdims=True)\n",
        "    return (images - mean) / (std + 1e-7)\n",
        "\n",
        "\n",
        "x_train_standardized = standardize_images(x_train.astype('float32'))\n",
        "print(f\"\\nStandardized mean: {x_train_standardized.mean():.6f}\")\n",
        "print(f\"\\nStandardized std: {x_train_standardized.std():.4f}\")"
      ],
      "metadata": {
        "id": "VGXnHz_JV89l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11e2c8b-70f1-4748-d428-0d06057c0c0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 Dataset Overview:\n",
            "Training set shape: (50000, 32, 32, 3)\n",
            "Training labels shape: (50000, 1)\n",
            "Test set shape: (10000, 32, 32, 3)\n",
            "Test labels shape: (10000, 1)\n",
            "Data type: uint8\n",
            "Min pixel value: 0\n",
            "Max pixel value: 255\n",
            "Data After Normalization:\n",
            "Normalized training data type: float32\n",
            "Normalized min value: 0.0000\n",
            "Normalized max value: 1.0000\n",
            "Normalized mean: 0.4734\n",
            "Normalized std: 0.2516\n",
            "\n",
            "Alternstive approach: Standardizartion\n",
            "\n",
            "Standardized mean: -0.000002\n",
            "\n",
            "Standardized std: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1 D&A**\n",
        "# **Discussion:**\n",
        "1. I `loaded` the **CIFAR-10 dataset** using a `built-in function(cifar10.load_data())`  from the **Keras library**.\n",
        "2. **CIFAR-10 dataset** is a subset of *80 million tiny images* and consists of `60,000 32x32 RGB color images`.\n",
        "3. The **Normalization approach** : I converted the datatype to `float32` and divided every pixel value by 255.0.\n",
        "4. This scaled the data from its `original range` of `[0, 255]` to a `new range` of `[0.0, 1.0]`.\n",
        "\n",
        "# **Analysis:**\n",
        "\n",
        "1. **Training Set Shape:** `50000`.\n",
        "2. **Test Set Shape:** `10000`.\n",
        "3. **Data type:** `Unit8`.\n",
        "4. **What if we train an autoencoder without normalization?**\n",
        "\n",
        "    Ans: If we trained without an autoencoder normalization, the model would likely `fail to converge`. The `large pixel values` (0-255) would lead to `very large gradients` during `backpropagation`. This can cause `\"exploding gradients,\"` where the model's weights update so drastically that they become NaN (Not a Number), and the `model might break`.\n",
        "5. **Alternative technique needed to perform pre-processing step?**\n",
        "\n",
        "    Ans:Alternative preprocessing step is `standardization`: subtracting the mean and dividing by the standard deviation of the dataset. However, for image data where pixel values have a fixed, known range (0,255), scaling to [0, 1] which I just implemented to showcase the output `Standardized mean: -0.000002` & `Standardized std: 1.0000`. You can also perform  `Rotation, flipping, shifting` (though not typically used for autoencoders)."
      ],
      "metadata": {
        "id": "acNiqdACj6yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Q2) EXPLORATORY DATA ANALYSIS(EDA):**\n"
      ],
      "metadata": {
        "id": "J7twxgty0_AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EDA on CIFAR-10 DATASET"
      ],
      "metadata": {
        "id": "Z02F7Ydaipy3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EZwV4l9207hL"
      }
    }
  ]
}